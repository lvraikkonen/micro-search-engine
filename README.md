# micro-search-engine

## 构建索引

倒排记录表 postings_lists，对倒排记录表序列化成一个长的字符串，写入到一个单元格，读取的时候再反序列化

构建倒排索引过程，扫描每个文档

- tf：记录该词项出现的次数，即词项频率(tf)
- ld：文档长度
- df：某词项在不同文档中出现的次数，即文档频率(df)

## 检索模型

### 基于概率的BM25模型

给定一个查询Q和一篇文档d，d对Q的BM25得分公式为

BM25score(Q,d)=∑t∈Qw(t,d)

w(t,d)=qtfk3+qtf×k1×tftf+k1(1−b+b×ld/avg_l)×log2N−df+0.5df+0.5

公式中变量含义如下：

- qtf：查询中的词频
- tf：文档中的词频
- ld：文档长度
- avg_l：平均文档长度
- N：文档数量
- df：文档频率
- b,k1,k3：可调参数

这个公式看起来很复杂，我们把它分解一下，其实很容易理解。第一个公式是外部公式，一个查询Q可能包含多个词项，比如“苹果手机”就包含“苹果”和“手机”两个词项，我们需要分别计算“苹果”和“手机”对某个文档d的贡献分数w(t,d)，然后将他们加起来就是整个文档d相对于查询Q的得分。

第二个公式就是计算某个词项t在文档d中的得分，它包括三个部分。第一个部分是词项t在查询Q中的得分，比如查询“中国人说中国话”中“中国”出现了两次，此时qtf=2，说明这个查询希望找到的文档和“中国”**更**相关，“中国”的权重应该更大，但是通常情况下，查询Q都很短，而且不太可能包含相同的词项，所以这个因子是一个常数，我们在实现的时候可以忽略。

第二部分类似于[TFIDF模型](https://en.wikipedia.org/wiki/Tf–idf)中的TF项。也就是说某个词项t在文档d中出现次数越多，则t越重要，但是文档长度越长，tf也倾向于变大，所以使用文档长度除以平均长度ld/avg_l起到某种归一化的效果，k1和b是可调参数。

第三部分类似于[TFIDF模型](https://en.wikipedia.org/wiki/Tf–idf)中的IDF项。也就是说虽然“的”、“地”、“得”等停用词在某文档d中出现的次数很多，但是他们在很多文档中都出现过，所以这些词对d的贡献分并不高，接近于0；反而那些很稀有的词如”糖尿病“能够很好的区分不同文档，这些词对文档的贡献分应该较高。

所以根据BM25公式，我们可以很快计算出不同文档t对查询Q的得分情况，然后按得分高低排序给出结果。			